# -*- coding: utf-8 -*-
import scrapy
import logging
import time
import random
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

class Baj58HtmlNewSpider(scrapy.Spider):
    name = 'baj_58_html_new'
    siteType = 5  # 表示类型58同城
    custom_settings = {
      'DOWNLOADER_MIDDLEWARES': {
        'scrapy.downloadermiddlewares.retry.RetryMiddleware': 10,
        # 'scrapy_baj.middlewares.ScrapyBajDownloaderMiddleware': 543,
      },
      'ROBOTSTXT_OBEY': False,
      # 'DOWNLOAD_TIMEOUT': 30,
      # 'DOWNLOAD_DELAY': 30
    }
    driver = webdriver.Chrome('C:\\ProgramInstall\\chromedriver91_win32\\chromedriver.exe')
    allowed_domains = ['sh.58.com']
    start_urls = ['https://sh.58.com/jiazhuang/pn11/?key=%E5%AE%B6%E5%BA%AD%E8%A3%85%E4%BF%AE&final=1&classpolicy=huangyezonghe_B&PGTID=0d300261-0000-2c67-558b-d311eb43ae38&ClickID=5']

    def parse(self, response):
        if('sh.58.com/jiazhuang/pn' in response.url):
            listSelector = response.css('tr:not(.none) div.tdiv>a.ac_linkurl')
            if(len(listSelector) == 0):
                logging.error('没有爬到网页列表')
                return
            # urllist = listSelector.attrib['href']
            urlList = []
            # for i,item in enumerate(listSelector):
            item = listSelector[0]
            url = item.attrib['href']
            urlList.append(url)
            self.driver.get(url)
            WebDriverWait(self.driver, 100).until(
                EC.visibility_of_element_located((By.CSS_SELECTOR, "div.item-btn.clearfix a"))
            )
            self.driver.find_element_by_css_selector('div.item-btn.clearfix a').click()
            logging.debug('telephone_clicked_in_middleware')
            # first url callback here
            time.sleep(1 + random.randint(1,5))
            self.driver.save()
        else:
            listSelector = response.css('div.infocard__container__item__main')
            if(listSelector == None or len(listSelector) == 0):
                logging.error('detail_page_load_wrong, url is: ' + response.url)
                return
            type = listSelector[0].css('::text').get().strip()
            serviceAreaEle = listSelector[1]
            serviceArea = ''
            for i, item in enumerate(serviceAreaEle.css('a::text')):
                serviceArea = serviceArea+ item.get().strip() + ' '
            serviceArea.strip()

            nameSelector = response.css('div.infocard__container__item--contact div.infocard__container__item__main::text')
            name = nameSelector.get().strip()
            addressSelector = response.css('div.infocard__container__item--shopaddress div.infocard__container__item__main')

            address = ''
            for i,item in enumerate(addressSelector[0].css('a::text')):
                address = address + item.get().strip() + ' '
            address = address.strip()

            phone = ''
            phoneSelector = response.css('div.tel_num.clearfix span.num_cont::text')
            if(phoneSelector != None and len(phoneSelector) > 0):
                phone = phoneSelector.get()
            phoneSelector = response.css('div.dialog_phone div.nowlt_tel span::text')
            if(phoneSelector != None and len(phoneSelector) > 0):
                phone = phoneSelector.get().split(' ')[1]
            yield {
                'type': type,
                'serviceArea': serviceArea,
                'name': name,
                'address': address,
                'phone': phone,
                'sourceId': 5
            }
        urlTest = ""

